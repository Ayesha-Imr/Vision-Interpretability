This segment focuses on **activation maximization** as a way of probing and visualizing what different parts of a convolutional neural network respond to. 
Building on the intuition developed in Segment 01, participants should approach this section as an exploratory exercise: choosing what to optimize, deciding how to visualize results, and reflecting on what those results suggest about internal representations.
Use Pytorch, Lucent Library (or something better if you can find it), InceptionV1 model and get activation maximizations for **first 10 neurons of mixed4a layer on InceptionV1**

Add your notebooks in submissions folder, with the notebook name in the following format:
github-username__segment_2_activation_maximization.ipynb
